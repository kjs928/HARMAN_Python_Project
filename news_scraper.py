import urllib.request
import urllib.parse
import json
import pandas as pd
import os
from datetime import datetime

# âœ… GitHub Actionsì—ì„œ í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
client_id = os.getenv("NAVER_CLIENT_ID")
client_secret = os.getenv("NAVER_CLIENT_SECRET")

# âœ… ê²€ìƒ‰í•  í‚¤ì›Œë“œ ëª©ë¡
keywords = ["ë°˜ë„ì²´", "ìŠ¤ë§ˆíŠ¸í°"]

# âœ… ê°€ì ¸ì˜¬ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì„¤ì • (ìµœëŒ€ 100ê°œ)
result_count = 5

# âœ… ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
all_results = []

# âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API ìš”ì²­ ë° ê²°ê³¼ DataFrame ë³€í™˜
for keyword in keywords:
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display={result_count}"

    # ìš”ì²­ ê°ì²´ ìƒì„± ë° í—¤ë” ì¶”ê°€
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)

    # API ìš”ì²­ ë° ì‘ë‹µ ì²˜ë¦¬
    try:
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            response_body = response.read()
            response_json = json.loads(response_body.decode('utf-8'))  # JSON íŒŒì‹±

            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ DataFrameì— ì €ì¥
            news_list = []
            for item in response_json['items']:
                # âœ… pubDate ë‚ ì§œ ë³€í™˜ (YYYY-MM-DD, ì‹œê°„ ì œê±°)
                try:
                    pub_date = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S %z")
                    pub_date = pub_date.strftime("%Y-%m-%d")  # ì‹œê°„(HH:MM:SS) ì œê±°
                except ValueError:
                    pub_date = item['pubDate']  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê°’ ìœ ì§€

                news_list.append([
                    keyword,               # ê²€ìƒ‰ í‚¤ì›Œë“œ
                    pub_date,              # ë³€í™˜ëœ ë‰´ìŠ¤ ê²Œì‹œ ë‚ ì§œ (YYYY-MM-DD)
                    item['title'],         # ë‰´ìŠ¤ ì œëª©
                    item['description'],   # ë‰´ìŠ¤ ìš”ì•½
                    item['link']           # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬
                ])

            # ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ì²´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_results.extend(news_list)

        else:
            print(f"Error Code: {rescode}")

    except Exception as e:
        print(f"Error: {e}")

# âœ… DataFrame ìƒì„± (ì»¬ëŸ¼ëª… ìˆ˜ì •)
columns = ['keyword', 'date', 'title', 'summary', 'url']
df = pd.DataFrame(all_results, columns=columns)

# âœ… CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
csv_filename = "news_results.csv"

# âœ… ê¸°ì¡´ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì¤‘ë³µ ë°©ì§€)
if os.path.exists(csv_filename):
    existing_df = pd.read_csv(csv_filename, encoding='utf-8-sig')

    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„° ê²°í•© í›„ ì¤‘ë³µ ì œê±°
    combined_df = pd.concat([existing_df, df]).drop_duplicates(subset=['title', 'date'], keep='last')

    # âœ… CSV íŒŒì¼ ë®ì–´ì“°ê¸° (ì¤‘ë³µ ì œê±° í›„ ì €ì¥)
    combined_df.to_csv(csv_filename, mode='w', index=False, encoding='utf-8-sig')

else:
    # âœ… ìƒˆ íŒŒì¼ ìƒì„±
    df.to_csv(csv_filename, mode='w', index=False, encoding='utf-8-sig')

print(f"\nğŸ“‚ ê²€ìƒ‰ ê²°ê³¼ê°€ '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
